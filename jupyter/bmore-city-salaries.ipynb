{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baltimore City Employee Salaries\n",
    "\n",
    "*If you're viewing this on your phone, I'd recommend enabling desktop mode. In Google Chrome, you can do so by tapping the three dots at the top right of your screen. `Desktop Site` usually has a checkbox next to it that you fill to enable the change. You can zoom in and out of any section with your fingers. My apologies for the hassle and thanks for reading!*\n",
    "\n",
    "Here, I go through an exploratory analysis of Baltimore city employee salaries. I obtained all data through the City of Baltimore's [Open Baltimore Data](https://data.baltimorecity.gov/datasets/baltimore::baltimore-city-employee-salaries-new/about) platform (OBD).\n",
    "\n",
    "I created a small Python function that batches calls to the OBD Rest API. I connected the GitHub repo I stored the python code in to a gcloud source repo. Each time I push a change to the `master` branch, GH notifies gcloud and Cloud Build uses the updated cloud source repo to deploy a new version to Cloud Function. Since OBD appears to only update the data once per year or so, I run the function manually. However, Cloud Scheduler would run my function at any interval I want using cron. \n",
    "\n",
    "Once the function finishes querying OBD, it stores the data in a `csv` in Cloud Storage. From there, I connect the `csv` to a BigQuery table. I considered updating the function to write directly to the BigQuery table, but I want to see how regularly OBD updates this data set going forward and if they change the schema. They've changed the schema for this dataset at least once that I've seen. I'll add some other details about this data set and a flow chart in the technical notes below.\n",
    "\n",
    "## Technical Notes and Disclosures\n",
    "- OBD only has one name field, which made it difficult to group records by person for analysis. For example, I previously combined the `firstName`, `lastName`, and `middleInitial` fields with `AgencyID` to create an `employeeSlug` that I use to track workers across organizations. With just the `Name` and `AgencyID` fields to work with in this release, tracking individual workers is difficult, though not impossible. It'll definitely be the work of a future analysis. This initial analysis focusses on agency-level salary measures.\n",
    "- I excluded salary records where the agency had less than 1000 salary records total or the record omitted the `HireDate` field. I wanted to keep the initial anaylsis as robust as possible, so I elected to clean the data in this way.\n",
    "- I regrouped the raw `AgencyName` values because the data set duplicated some agency names, made distinctions inside of an agency I didn't want to keep, etc. For example, OBD broke out \"Rec & Parks\" to \"Rec & Parks - Parks\", \"Rec & Parks - part-time\", \"Rec & Parks - Admin\", etc.\n",
    "\n",
    "![City Salaries Data Set API Request Flow](./city-salaries-request-flow.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Things First\n",
    "\n",
    "Gotta get the data in! As I noted in the beginning, I stored this data in a BigQuery table. So the first step is to query the table and bring in the salary and employee name data I want. After I created a Google Cloud account and project, I installed the Google Cloud SDK for Python. Lots of trial and error, but overall a pretty straigtforward process. Unfortunately, I don't have a very comprehensive set of links to show y'all how to get started on Google Cloud if you wanted to recreate this setup, but I'll list the basic steps below:\n",
    "\n",
    "1. Create a Google Cloud account (pretty easy if you already have a gmail, also easy if you don't)\n",
    "2. Create a Google Cloud project\n",
    "3. Create a BigQuery table\n",
    "4. Install the Cloud Client Libraries for Python\n",
    "5. Install the gcloud CLI\n",
    "6. [Set up Application Default Credentials](https://cloud.google.com/docs/authentication/provide-credentials-adc#local-dev)\n",
    "    - I do have a link for this! and it's what allows me to just supply a `project_id` and nothing else to connect to my gcloud instances. Highly recommend this and it was very easy.\n",
    "\n",
    "Once all that is done, you can run some version of the code below and bring your data in for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil import relativedelta as rd\n",
    "\n",
    "# build client to connect to open-baltimore project\n",
    "project_id = \"open-baltimore-data\"\n",
    "client = bigquery.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import employee name info\n",
    "employee_salaries_query = client.query(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        info.employeeSlug,\n",
    "        main.objectId,\n",
    "        TRIM(REGEXP_REPLACE(main.agencyName, r'\\(.*?\\)', '')) as agencyName,\n",
    "        main.agencyId,\n",
    "        main.annualSalary,\n",
    "        main.fiscalYear,\n",
    "        main.hireDate\n",
    "    FROM city_employee_salaries.main as main\n",
    "    LEFT JOIN city_employee_salaries.employee_info as info\n",
    "    ON main.ObjectId = info.ObjectId\n",
    "    \"\"\"\n",
    ")\n",
    "employee_salaries = employee_salaries_query.result().to_dataframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, Cleaning, Cleaning\n",
    "\n",
    "Here, I created my own dictionary for translating existing city agency names to my own. Then I used `map` to populate a `cleanAgencyName` column with the new names. `map` loops over each record in the existing `agencyID` field, checks my dictionary for a match, then returns the matches in the new column. It's a super fast function and the syntax is very simple. Lastly, I converted the `hireDate` field to `datetime` format so I can calculate `tenure`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean fields for analysis\n",
    "agency_dict =  {\n",
    "    \"A01\": \"Mayors Office\",\n",
    "    \"A02\": \"City Council\",\n",
    "    \"A02\": \"Mayors OED\",\n",
    "    \"A04\": \"Rec & Parks\",\n",
    "    \"A05\": \"MONSE\",\n",
    "    \"A06\": \"Housing & Community Dev\",\n",
    "    \"A08\": \"M-R Human Services\",\n",
    "    \"A09\": \"Liquor License Board\",\n",
    "    \"A10\": \"Mayors Office of Children & Families\",\n",
    "    \"A11\": \"Office of the Inspector General\",\n",
    "    \"A12\": \"Finance\",\n",
    "    \"A14\": \"Finance\",\n",
    "    \"A15\": \"Comptrollers Office\",\n",
    "    \"A16\": \"Comptrollers Office\",\n",
    "    \"A17\": \"Finance\",\n",
    "    \"A18\": \"Finance\",\n",
    "    \"A19\": \"City Planning\",\n",
    "    \"A23\": \"Finance\",\n",
    "    \"A24\": \"Comptroller - Audits\",\n",
    "    \"A26\": \"M-R Labor Commissioner\",\n",
    "    \"A28\": \"Wage Commissioner\",\n",
    "    \"A29\": \"States Attorneys Office\",\n",
    "    \"A30\": \"Law Department\",\n",
    "    \"A31\": \"Circuit Court\",\n",
    "    \"A32\": \"Finance\",\n",
    "    \"A33\": \"Legislative Reference\",\n",
    "    \"A35\": \"Elections\",\n",
    "    \"A37\": \"Orphans Court\",\n",
    "    \"A38\": \"Sheriffs Office\",\n",
    "    \"A39\": \"311\",\n",
    "    \"A40\": \"BCIT\",\n",
    "    \"A41\": \"DPW - Admin\",\n",
    "    \"A44\": \"M-R Cable & Comms\",\n",
    "    \"A46\": \"Environmental Control Board\",\n",
    "    \"A49\": \"Transportation\",\n",
    "    \"A50\": \"DPW - Waste & Wastewater\",\n",
    "    \"A51\": \"Office of Equity & Civil Rights\",\n",
    "    \"A52\": \"Employee Retirement System\",\n",
    "    \"A53\": \"Finance\",\n",
    "    \"A54\": \"Retirement - Fire & Police\",\n",
    "    \"A57\": \"City Council Services\",\n",
    "    \"A64\": \"Fire Department\",\n",
    "    \"A65\": \"Health Department\",\n",
    "    \"A67\": \"Rec & Parks\",\n",
    "    \"A68\": \"Rec & Parks\",\n",
    "    \"A70\": \"DPW - Solid Waste\",\n",
    "    \"A73\": \"Municipal Zoning & Appeals\",\n",
    "    \"A75\": \"Enoch Pratt Free Library\",\n",
    "    \"A83\": \"Human Resources\",\n",
    "    \"A84\": \"Transportation\",\n",
    "    \"A85\": \"General Services\",\n",
    "    \"A86\": \"War Memorial Commission\",\n",
    "    \"A88\": \"Comptroller - Comms\",\n",
    "    \"A90\": \"Transportation\",\n",
    "    \"A91\": \"Convention Center\",\n",
    "    \"A99\": \"Police Department\",\n",
    "    \"A9\": \"Police Department\",\n",
    "    \"B49\": \"Transportation\",\n",
    "    \"B68\": \"Rec & Parks\",\n",
    "    \"B70\": \"DPW - Solid Waste\",\n",
    "    \"BPD\": \"Police Department\",\n",
    "    \"C90\": \"Transportation - Crossing Guards\",\n",
    "    \"P04\": \"Rec & Parks\",\n",
    "    \"P65\": \"Health Department\",\n",
    "    \"P83\": \"HR Test Monitor\",\n",
    "    \"R01\": \"R01\",\n",
    "    \"U01\": \"U01\",\n",
    "    \"SCS\": \"Special City Services\",\n",
    "    \"W02\": \"Youth Summer Works\",\n",
    "    \"W03\": \"Youth Cust\",\n",
    "    \"W07\": \"Youth Temp Adult\",\n",
    "    \"W08\": \"TANF Cust\"\n",
    "}\n",
    "employee_salaries['cleanAgencyName'] = employee_salaries['agencyId'].map(agency_dict)\n",
    "employee_salaries = employee_salaries[employee_salaries[\"hireDate\"].notnull()]\n",
    "employee_salaries['hireDate'] = pd.to_datetime(employee_salaries[\"hireDate\"], unit=\"ms\")\n",
    "# may need to implement check and ensure tenure across unique employees is the same\n",
    "employee_salaries['tenure'] = \\\n",
    "    employee_salaries['hireDate'].map(lambda hire_date: rd.relativedelta(dt.datetime.now(), hire_date).years)                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of records per city agency\n",
    "agency_record_count = employee_salaries.groupby([\"cleanAgencyName\"], as_index=False).agg(\n",
    "    salaryRecords=pd.NamedAgg(column=\"cleanAgencyName\", aggfunc=\"count\")\n",
    "    )\n",
    "agencies_with_1000_records = agency_record_count[agency_record_count[\"salaryRecords\"] >= 1000][\"cleanAgencyName\"].values.tolist()   \n",
    "# calculate mean salary, max salary, min salary, growth, salary records, tenure, average raise by employee and agency\n",
    "employee_salary_quality = employee_salaries.groupby([\"employeeSlug\", \"cleanAgencyName\"], as_index=False).agg(\n",
    "    medSalary=pd.NamedAgg(column=\"annualSalary\", aggfunc=\"median\"),\n",
    "    highestSalary=pd.NamedAgg(column=\"annualSalary\", aggfunc=\"max\"),\n",
    "    lowestSalary=pd.NamedAgg(column=\"annualSalary\", aggfunc=\"min\"),\n",
    "    growth=pd.NamedAgg(column=\"annualSalary\", aggfunc=lambda salary: max(salary) - min(salary)),\n",
    "    salaryRecords=pd.NamedAgg(column=\"annualSalary\", aggfunc=\"nunique\"),\n",
    "    tenure=pd.NamedAgg(column=\"tenure\", aggfunc=\"first\"),\n",
    "    avgRaise=pd.NamedAgg(column=\"annualSalary\", aggfunc=lambda salary: (max(salary) - min(salary)) / len(salary))\n",
    "    )\n",
    "agency_salary_quality = employee_salary_quality.groupby([\"cleanAgencyName\"], as_index=False).agg(\n",
    "    medSalary=pd.NamedAgg(column=\"medSalary\", aggfunc=\"median\"),\n",
    "    medHighestSalary=pd.NamedAgg(column=\"highestSalary\", aggfunc=\"median\"),\n",
    "    medLowestSalary=pd.NamedAgg(column=\"lowestSalary\", aggfunc=\"median\"),\n",
    "    medGrowth=pd.NamedAgg(column=\"growth\", aggfunc=\"median\"),\n",
    "    medTenure=pd.NamedAgg(column=\"tenure\", aggfunc=\"median\"),\n",
    "    medRaise=pd.NamedAgg(column=\"avgRaise\", aggfunc=\"median\")\n",
    "    ).query(\"cleanAgencyName in @agencies_with_1000_records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
